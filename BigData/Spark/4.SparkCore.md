# 4.	SparkCore

## 4.1	RDD概述

### 4.1.0	为什么需要RDD

在分布式计算中，我们需要的功能：

- 分区控制(数据分块)
- Shuffle控制(不同分区上的数据交互)
- 数据存储、数据序列化、数据发送
- 数据计算API
- ...

要完成这么多功能，Python内置的数据集合类型显然不能满足。在分布式框架中，我们需要一个统一的数据抽象对象来实现以上功能，这就是RDD。



### 4.1.1	什么是RDD

弹性数据集RDD(Resilient Distributed Dataset)，是Spark中最基本的数据抽象，表示一个不可变、可分区、元素可并行计算的集合。

- Dataset：数据集合，用于存放数据

> List、Dict、Array等数据集合都是本地集合，即所有数据都在一个进程内部，无法实现分布式

- Distributed： RDD中的数据是分布式存储的，因此可以实现分布式计算

> RDD中的数据是跨机器(跨进程)存储的

- Resilient: RDD中的数据可以存放在内存，也可以存放在硬盘中。

> RDD的大小可以动态扩充或缩减，并且可以 切换存放介质

<img src="Image/image-20230804170334946.png" alt="image-20230804170334946" style="zoom: 80%;" />

### 4.1.2	RDD五大特性

RDD有五大特性：

- RDD中有分区

> 分区是RDD存储的最小单位，一份RDD数据本质上是分割为了多个分区。 
>
> 分区是物理概念，而RDD是抽象概念
>
> 用一段代码展示RDD中的分区：
>
> ```python
> # 向Spark存储数字1~9，划分为3个分区
> rdd = sc.parallelize([1,2,3,4,5,6,7,8,9], 3)
> # glom()方法能够展示当前RDD的分区情况, collect()收集到本地
> print(rdd.glom().collect())
> # >>> [[1, 2, 3], [4, 5, 6], [7, 8, 9]]
> ```
>
> <img src="Image/image-20230804171321373.png" alt="image-20230804171321373" style="zoom: 67%;" />

- 计算方法会作用到每一个数据分片(分区)

> ```python
> >>> sc.parallelize([1,2,3,4,5,6,7,8,9], 3).glom().collect()
> >>> [[1, 2, 3], [4, 5, 6], [7, 8, 9]]
> >>> sc.parallelize([1,2,3,4,5,6,7,8,9], 3).map(lambda x: X*10).glom().collect()
> >>> [[10, 20, 30], [40, 50, 60], [70, 80, 90]]
> ```

- RDD间存在依赖关系（迭代计算关系）

> <img src="Image/image-20230804171829056.png" alt="image-20230804171829056" style="zoom: 50%;" />

- 对于K-V型RDD，可以自定义分区器

> 在Spark中，我们将存储数据格式为二元元组的RDD称为KV型RDD
>
> <img src="Image/image-20230804172040299.png" alt="image-20230804172040299" style="zoom: 50%;" />
>
> 

- 为了减少开销，RDD读取分区数据时会尽可能靠近数据所在地（比如Spark会在确保并行计算能力的前提下，尽可能让存放那一部分分片的设备从本地读取，从而避免网络传输的额外开销）



### 4.1.3	WordCount案例分析

![image-20230804173453499](Image/image-20230804173453499.png)



## 4.2	RDD编程

SparkRDD编程的程序入口对象是SparkContext对象，从编程角度上来说，SparkContext功能就是创建第一个RDD

### 4.2.1	创建RDD

RDD创建方式有两种：

- 通过并行化集合创建（本地集合对象->分布式RDD）
- 读取外部数据源（文件读取）

 **并行化创建RDD**：

```python
# 并行化创建对象, 调用SparkContext对象的parallelize()方法, 传入本地集合对象和分区数
# 若不指定分区数，默认值则依据集群拥有的CPU数量决定
rdd = sc.parallelize(data_collection, num_partitions)

# 对RDD对象调用getNumPartitions()方法获取该RDD对象的分区数
print(rdd.getNumPartitions())
# collect()方法将RDD(分布式集合)中每个分区数据都发送给Driver, 得到一个本地的Python list对象
# 即实现了分布式集合->本地集合
print(rdd.collect())
```

**读取文件创建RDD**：

```python
"""
调用SparkContext对象的textFile()方法，传入文件路径和最小分区数：
	文件路径可选本地路径，也可以是分布式文件系统路径，如HDFS
	Spark会自行估算当前文件的最小分区数，若传入值超出Spark认为可行的范围则参数失效
一般情况下，我们不对textFile()传入分区数
"""
rdd = sc.textFile(file_path, min_num_partitions)

"""
对于批量小文件读取, Spark提供了另外的API: wholeTextFile()
	其参数与textFile()相同
与textFile()不同的是, wholeTextFile()倾向于使用更少的分区读取数据, 以减少Shuffle几率提高效率
"""
rdd = sc.wholeTextFile(file_path)
```



### 4.2.2	RDD算子

我们将分布式集合对象上的API称为算子，它与方法/函数类似，只是针对分布式对象；而方法/函数针对本地对象

RDD算子分为两种：

- Transformation: 转换算子

> 定义：返回值为RDD的RDD算子，称为Transformation算子
>
> 特性：懒加载，如果没有Action算子则不工作

- Action: 动作算子

> 定义：返回值不为RDD的RDD算子，称为Action算子

<img src="Image/image-20230804175805671.png" alt="image-20230804175805671" style="zoom:67%;" />

对这两类算子来说，Transformation算子相当于构建工作计划，而Action算子是执行计划的指令。

如果没有Action算子，Transformation算子间的迭代关系就像没通电的流水线，直到Action算子到来，这个数据处理流水线才开始工作。



### 4.2.3 常见Transformation算子

#### 4.2.3.1	Map算子

Map算子，是将RDD数据一条条处理，返回新的RDD

其语法为：

```python
rdd.map(func)
"""
func: f:(T) -> U
f: 表示这是一个函数, (T) -> U表示函数定义
	()表示传入参数, (T)表示传入一个参数, ()表示不传入参数
	T、U都是泛型代称
	-> U表示返回值
"""
# 示例：
def add(data):
    return data * 10
print(rdd.map(add).collect())
# 对于一行可以解决的函数, 也可以直接用Lambda表达式传入匿名函数
print(rdd.map(lambda x: x*10).collect())
```



#### 4.2.3.2	flatMap算子

flatMap算子是对RDD先执行Map操作，然后解除嵌套：

> 解除嵌套：
>
> ```python
> >>> lst = [[1,2,3],[4,5,6],[7,8,9]]
> # 解除嵌套
> >>> lst = [1,2,3,4,5,6,7,8,9]
> ```

```python
rdd = sc.parallelize(['hadoop spark hadoop', 'spark hadoop spark', 'hadoop flink spark'])

print(rdd.map(lambda x: x.split("")).collect())
>>> [['hadoop', 'spark', 'hadoop'], ['spark', 'hadoop', 'spark'], ['hadoop', 'flink', 'spark']]

print(rdd.flatMap(lambda x: x.split('')).collect())
>>> ['hadoop', 'spark', 'hadoop', 'spark', 'hadoop', 'spark', 'hadoop', 'flink', 'spark']
```



#### 4.2.3.3	reduceByKey算子

针对KV型RDD，reduceByKey算子可以自动按Key分组，然后根据传入的聚合逻辑，完成组内数据(value)的聚合操作

```python
rdd.reduceByKey(func)
# func: (V, V) -> V
# 接受两个传入参数V(类型一致), 返回值与传入参数类型相同

rdd = sc.parallelize([('a', 1), ('a', 1), ('b', 1), ('b', 1), ('b', 1)])
res = rdd.reduceByKey(lambda a, b: a+b)
print(res.collect())
>>> [('b', 3), ('a', 2)]
```

注意：reduceByKey接受的函数，只负责聚合Value而不处理分组，即只关心Value而不关心Key

<img src="Image/image-20230804182853789.png" alt="image-20230804182853789" style="zoom:67%;" />

#### 4.2.3.4 mapValues算子

mapValues算子针对**二元元组**的RDD，对其内部的**Value**执行**map**操作

```python
rdd.mapValues(func)
# func: (V) -> U
# 传入的参数是二元元组的Value, 即方法只处理Value
```



#### 4.2.3.5	WordCount回顾

<img src="Image/image-20230804183421683.png" alt="image-20230804183421683" style="zoom:67%;" />



#### 4.2.3.6	groupBy算子

groupBy算子能够对RDD数据进行分组

```python
rdd.groupBy(func)
"""
	func: (T) -> K
	函数传入一个参数，返回一个返回值，类型可以不同
	函数拿到返回值后，将所有相同返回值的放入一个group中
	分组完成后，每个组是一个二元元祖，key是返回值，所有同组的数据放入一个迭代器对象中作为Value
	
	可以理解为, groupBy传入的函数意思是：通过该函数，确定按照谁分组(返回谁)
	分组规则与SQL一致，即相同的在一个组(Hash分组)
"""

rdd = sc.parallelize([1,2,3,4,5])
# 分组，将数字分层，偶数和奇数分开
rdd2 = rdd.groupBy(lambda num: 'even' if (num%2==0) else 'odd')

# 将RDD2元素的value转为list, 以便print输出
rdd2 = rdd2.map(lambda x: (x[0], list(x[1])).collect())
print(rdd2)
>>> [('even', [2, 4]), ('odd', [1, 3, 5])]
```



#### 4.2.3.7	Filter算子

Filter算子能够只保留需要的数据，过滤掉不需要的数据

```python
rdd.filter(func)
# func: (T) -> bool 只保留返回值为True的数据

rdd = sc.parallelize([1,2,3,4,5])
# 通过Filter算子, 只保留偶数
rdd2 = rdd.filter(lambda x: x%2==0).collect()
print(rdd2)
>>> [2, 4]
```



#### 4.2.3.8	distinct算子

distinct算子能够去除重复数据

```python
rdd.distinct(param)
# 这里的param指的是去重分区数量，一般不用传入

rdd = sc.parallelize([1, 2, 2, 3, 4, 5, 5])
print(rdd.distinct().collect())
>>> [1,2,3,4,5]

rdd2 = sc.parallelize([('a', 1), ('a', 1), ('b', 3)])
print(rdd2.distinct().collect())
>>> [('a', 1), ('b', 3)]
```



#### 4.2.3.9	union算子

union算子将两个RDD合并为一个RDD并返回

```python
rdd.union(rdd2)
# 注意：union操作只合并数据并不去重，且合并的两个RDD数据类型可以不同

rdd1 = sc.parallelize([1, 1, 3, 3])
rdd2 = sc.parallelize(['a', 'b', 'c'])
print(rdd1.union(rdd2).collect())
>>> [1, 1, 3, 3, 'a', 'b', 'c']
```



#### 4.2.3.10	join算子

join算子能够对两个RDD执行join操作，实现SQL的内/外连接

注意：**join算子只能用于二元元组**

```python
# join算子以二元元组的Key作为关联
rdd.join(rdd2)	# 内连接
rdd.leftOuterJoin(rdd2)	# 左外连接
rdd.rightOuterJoin(rdd2)	# 右外连接

rdd1 = sc.parallelize([(1001, '张三'), (1002, '李四'), (1003, '王五'), (1004, '赵六')])
rdd2 = sc.parallelize([(1001, '销售部'), (1002, '研发部')])

print(rdd1.join(rdd2).collect())
>>> [(1001, ('张三', '销售部')), (1002, ('李四', '研发部'))]

# 相当于rdd2.rightOuterJoin(rdd1)
print(rdd1.leftOuterJoin(rdd2).collect())
>>> [(1001, ('张三', '销售部')), (1002, ('李四', '研发部'))， (1003, ('王五', None)), (1004, ('赵六', None))]
```



#### 4.2.3.11	intersection算子

intersection算子求两个RDD的交集，返回新的RDD

```python
rdd.intersection(rdd2)

rdd1 = sc.parallelize([('a', 1), ('b', 1)])
rdd2 = sc.parallelize([('a', 1), ('c', 1)])
print(rdd1.intersection(rdd2).collect())
>>> [('a', 1)]
```



#### 4.2.3.12	glom算子

glom算子将RDD数据加上嵌套，嵌套格式由**分区情况**决定

```python
rdd.glom()
# 假设RDD数据[1,2,3,4,5]有2个分区, 那么glom后可能会变成[[1,2,3], [4,5]]
```



#### 4.2.3.13	groupByKey算子

groupByKey算子针对**KV型KDD**，自动按Key分组

```python
rdd.groupByKey()
# groupByKey()只作用于KV型KDD, 因此与groupBy()不同的是，它分组后只保留原本元素的Value

rdd = sc.parallelize([('a', 1), ('a', 1), ('b', 1), ('b', 2)])
grouped_rdd = rdd.groupByKey()
print(grouped_rdd.map(lambda x: (x[0], list(x[1]))).collect())
>>> [('a', [1, 1]), ('b', [1, 2])]
```

 

#### 4.2.3.14	sortBy算子

sortBy算子对RDD数据排序，排序依据基于指定

注意：**排序时只保证Executor内有序即局部有序**，要全局有序则要指定numPartitions=1

```python
rdd.sortBy(func, ascending=False, numPartitions=1)
# func: (T) -> U: 告知按KDD中哪个数据排序, 如lambda x: x[1]表示用RDD中第二列数据排序
# ascengding: 是否升序排列, 默认为True
# numPartitions: 用多少分区排序

rdd = sc.parallelize([('c', 2), ('b', 1), ('a', 4), ('f', 7), ('e', 1)])
print(rdd.sortBy(lambda x: x[1], ascending=True, numPartitions=1).collect())
>>> [('b', 1), ('e', 1), ('c', 2), ('a', 4), ('f', 7)]
```



#### 4.2.3.15	sortByKey算子

sortBykey算子只针对KV型RDD，按Key排序

```python
sortByKey(ascending=True, numPartitions=None, keyfunc=<function RDD.<lambda>>)
# keyfunc: 在排序前对Key进行处理, 语法为(k)->U
# 注意：keyfunc只改变在排序时key的值，不改变最终输出的值

rdd = sc.parallelize([('A', 1), ('a', 1), ('b', 1), ('E', 1)])
print(rdd.sortByKey().collect())
>>> [('A', 1), ('E', 1), ('a', 1), ('b', 1)]

print(rdd.sortByKey(keyfunc=lambda k:str(k).lower()).collect())
>>> [('A', 1), ('a', 1), ('b', 1), ('E', 1)]
```



### 4.2.4	常见Action算子

#### 4.2.4.1	countByKey算子

countByKey算子一般用于KV型RDD，用于统计每个Key出现的次数，返回类型为collections.defaultdict，返回值为Key-Count

```python
rdd.countByKey()

rdd = sc.textFile('./word.txt')
rdd2 = rdd.flatMap(lambda x: x.split('')).map(lambda x: (x, 1))
res = rdd2.countByKey()
print(res)
>>> defaultdict(<alss 'int'>, {'hello': 3, 'spark': 1, 'hadoop': 1})
```



#### 4.2.4.2	collect算子

collect算子将RDD各分区内的数据，统一收集到Driver中，得到一个list对象

**注意**：collect算子将RDD各分区数据都会拉取到Driver，使用该方法要确保数据集大小不会造成Driver内存溢出



#### 4.2.4.3	reduce算子

reduce算子对RDD按传入逻辑进行聚合

**注意**：reduce算子是Action算子，而reduceByKey算子是Transformation算子

```python
rdd.reduce(func)
# func: (T, T) -> T 传入两个相同类型参数，返回1个相同类型参数

rdd = sc.parallelize(range(1, 6))
# 累加求和
print(rdd.reduce(lambda a, b: a+b))
>>> 15
```

执行流程如下：

<img src="Image/image-20230805153927991.png" alt="image-20230805153927991" style="zoom:67%;" />



#### 4.2.4.4	fold算子(了解)

fold算子与reduce类似，接受传入逻辑进行聚合，**聚合是带有初始值的**

这个初始值聚合，作用在分区内聚合和分区间聚合

```python
rdd.fold(init_num, func)
# 如对[[1, 2, 3], [4, 5, 6], [7, 8, 9]]聚合：
rdd = sc.parallelize(range(1, 10), 3)
print(rdd.fold(10, lambda a,b: a+b))
>>> 85

"""
分区内聚合：
	对第1个分区聚合时：初始值10+1+2+3=16
	对第2个分区聚合时：初始值10+4+5+6=25
	对第3个分区聚合时：初始值10+7+8+9=34
分区间聚合：
	初始值10+16+25+34=85
"""
```



#### 4.2.4.5	first算子

first算子取出RDD中第一个元素并直接返回

```python
>>> sc.parallelize([1,2,3].first())
>>> 3
```



#### 4.2.4.6	take算子

take算子取RDD的前N个算子，返回一个对应的list

```python
>>> sc.parallelize([3, 2, 1, 4, 5, 6]).take(5)
>>> [3, 2, 1, 4, 5]
```



#### 4.2.4.7	top算子

top算子先对RDD降序排序，然后取前N个返回一个对应list

```python
>>> sc.parallelize([3, 2, 1, 4, 5, 6].top(3))
>>> [6, 5, 4]
```



#### 4.2.4.8	count算子

count算子计算RDD中元素个数，直接返回数值

```python
>>> sc.parallelize(range(1, 6)).count()
>>> 5
```



#### 4.2.4.9	takeSample算子

takeSample算子从RDD中随机抽样数据

```python
takeSample(repeat: bool, num_samples: int, random_seed: int)
# repeat参数表示有无放回采样

>>> sc.parallelize([1, 1, 1, 1, 1]).takeSample(True, 8)
>>> [1, 1, 1, 1, 1, 1, 1, 1]
```



#### 4.2.4.10	takeOrdered算子

takeOrdered算子与top算子类似，但是为**升序排序**RDD并取前N个元素组成list返回

```python
rdd.takeOrdered(num_takes, orderfunc)
# num_takes: 要几个元素
# orderfunc: 对排序时的数据值更改，不影响结果

# 可以通过orderfunc实现升序和降序排序：
print(sc.parallelize([1, 3, 2, 4, 7, 9, 6], 1).takeOrdered(3))
>>> [1, 2, 3]

print(sc.parallelize([1, 3, 2, 4, 7, 9, 6], 1).takeOrdered(3, lambda x:-x))
>>> [9, 7, 6]
```



#### 4.2.4.11	foreach算子

foreach算子对RDD每个元素，执行传入的逻辑，没有返回值

当我们需要查看RDD元素值而不需要其返回值操作时，foreach会比collect效率更高

```python
rdd.foreach(func)
# func: (T) -> None

rdd = sc.parallelize([1, 3, 2, 4, 7, 9, 6])
# 对数据乘以10
r = rdd.foreach(lambda x:print(x*10))
>>> 10 30 20 40 70 90 60

print(r)
>>> None # foreach没有返回值
```



#### 4.2.4.12	saveAsTextFile算子

saveAsTextFile算子将RDD数据写入到文本文件中，支持本地写入和分布式文件系统写入

```python
rdd = sc.parallelize([1, 3, 2, 4, 7 , 9, 6], 3)
rdd.saveAsTextFile('hdfs://iot146:8020/output/test.txt')
```



#### 4.2.4.13	mapPartitions算子

mapPartitions算子与map算子类似，但map算子每次传递一个元素执行计算，而mapPartitions算子一次传递RDD的一个分区进行计算，这样能大大减少网络IO的开销，但要注意的是使用时要保证不会超出Executor的可用内存



#### 4.2.4.14	foreachPartitions算子

foreachPartitions算子与foreach算子类似，每次传递一个分区，大大减少网络IO的开销



#### 4.2.4.15	partitionBy算子

partitionBy算子能对RDD进行自定义分区

```python
rdd.partitionBy(num_partitions, partitionFunc)
# num_partitions: 重新分区后的分区数
# partitionFunc: 自定义分区规则
# partitionFunc: (K) -> int 传入任意类型参数，返回值为int类型
# 即将元素的Key传给函数，自定义函数逻辑，决定返回的分区编号，编号范围[0, num_partitions-1]

rdd = sc.parallelize(
	[('hadoop', 1), ('spark', 1), ('hello', 1), ('flink', 1), ('hadoop', 1), ('spark', 1)]
)

def process(k):
    if k == 'hadoop' or k == 'hello':
        return 0
    if k == 'spark':
        return 1
    return 2

print(rdd.partitionBy(3, process).glom().collect())
>>> [[('hadoop', 1), ('hello', 1), ('hadoop', 1)], [('spark', 1), ('spark', 1)], [('flink', 1)]]
```



#### 4.2.4.16	repartition算子

repartition算子同样对RDD重新分区，但只改变数量而不改变分区规则

**注意**：要慎重使用分区数量操作，一般除了全局排序时，并不关心分区

当改变分区数量时：	

- 影响并行计算（内存迭代的并行管道数量）
- 分区增加时，很容易导致shuffle

```python
rdd.repatition(N) # N为决定的新分区数
```



#### 4.2.4.17	coalesce算子

coalesce算子与repatition算子类似，但它比repatition算子更安全，当分区数量增加时，只有传入参数shuffle=True时才会执行，从而避免误操作导致的分区数量增加和开销增加

```python
>>> rdd = sc.parallelize([1, 2, 3, 4, 5], 3)

>>> rdd.repatition(1).getNumPartitions()
>>> 1
>>> rdd.repatition(5).getNumPartitions()
>>> 5

>>> rdd.coalesce(1).getNumPartitions()
>>> 1
# 当分区数量增加时，只有传入参数shuffle=True时才会执行
>>> rdd.coalesce(5).getNumPartitions()
>>> 3
>>> >>> rdd.coalesce(5, shuffle=True).getNumPartitions()
>>> 5
```



### 4.2.5	groupByKey和reduceByKey的区别

在功能上：

- groupByKey只能分组
- reduceByKey除了ByKey的分组功能外，还有reduce的聚合功能，因此它是一个分组聚合功能一体化的算子

在性能上：

​	当对数据执行分组+聚合时，reduceByKey的性能远高于groupByKey，因为groupByKey只能分组，因此它要先分组(shuffle)后聚合；而reduceByKey在分组内就先做了局部聚合，这样就大大减少了需要shuffle的数据。

<img src="Image/image-20230805162949536.png" alt="image-20230805162949536" style="zoom:67%;" />

![image-20230805163101811](Image/image-20230805163101811.png)



## 4.3	RDD持久化

### 4.3.1	RDD数据是过程数据

RDD之间进行迭代计算(Transformation转换)时，当执行启动，新RDD生成时，老RDD就消失了。

RDD数据是过程数据，只在处理过程存在，一旦处理完成就会消失。

> RDD的这个特性可以最大化利用计算资源，老旧RDD失效后就会被GC清理，为后续计算腾出内存空间

![image-20230805163525903](Image/image-20230805163525903.png)



### 4.3.2	RDD缓存

由于RDD数据是过程数据，为了能暂时保留RDD数据以供后续使用，要使用RDD缓存

Spark提供了RDD的缓存API，可以通过调用，将RDD数据保留在内存或硬盘

```python
# 当RDD不止一次被使用时，可以将其加入到缓存以减少重复计算
rdd.cache()	# 缓存到内存

rdd.persisit(StorageLevel.MEMORY_ONLY)	# 只缓存到内存, 和cache()一样
rdd.persisit(StorageLevel.MEMORY_ONLY_2)	# 只缓存到内存, 2个副本

rdd.persisit(StorageLevel.DISK_ONLY)	# 只缓存到硬盘
rdd.persisit(StorageLevel.DISK_ONLY_2)	# 只缓存到硬盘, 2个副本
rdd.persisit(StorageLevel.DISK_ONLY_3)	# 只缓存到硬盘, 3个副本

rdd.persisit(StorageLevel.MEMORY_AND_DISK)	# 先放内存，内存不够再放硬盘
rdd.persisit(StorageLevel.MEMORY_AND_DISK_2)	# 先放内存，内存不够再放硬盘, 2个副本

rdd.persisit(StorageLevel.OFFHEAP)	# 堆外内存(系统内存)

# 一般建议使用StorageLevel.MEMORY_AND_DISK
# 如果集群内存比较小，建议使用StorageLevel.DISK_ONLY，或者不用缓存，用CheckPoint

# 释放缓存的API
rdd.unpersisit()
```

缓存是**分散存储**的，即每个Executor只保存自己拥有分区上的数据

缓存在设计上认为是**不安全**（有丢失风险）的，因此它还会**保留RDD间的依赖关系**，一旦缓存丢失，可以基于依赖关系重新计算出其中的数据



### 4.3.3	RDD CheckPoint

CheckPoint技术，同样是保存RDD数据，但只支持硬盘存储

与缓存不同，CheckPoint技术设计上认为是**安全**的，同时**不保留RDD间的依赖关系**

CheckPoint在保存RDD数据时，将各分区数据收集起来**集中存储**，这与缓存的分散存储不同

![image-20230805165200371](Image/image-20230805165200371.png)

缓存与CheckPoint对比：

- CheckPoint无论分区多少，风险相同。缓存分区越多，风险越高
- CheckPoint支持写入HDFS，缓存只能写入到Executor本地。而HDFS是高可靠存储，因此CheckPoint设计安全
- CheckPoint不支持写内存，缓存可以，当缓存写入内存时，性能好于CheckPoint
- CheckPoint设计安全，因此不保留RDD依赖关系；缓存设计不安全，因此需要保留RDD依赖关系

使用CheckPoint：

```python
# 设置CheckPoint保存路径, 在Local模式下可以指定本地文件路径，集群模式下只支持HDFS
sc.setCheckPointDir('hdfs://iot146:8020/checkpoint/testDataBackUp')

rdd.checkpoint()
```



## 4.4	jieba库
